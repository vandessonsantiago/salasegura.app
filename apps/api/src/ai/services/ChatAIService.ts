import OpenAI from 'openai';
import { UserContext } from '../types/ai.types';
import { CacheService } from './CacheService';
import { MetricsService } from './MetricsService';

export class ChatAIService {
  private static openai: OpenAI | null = null;

  static initialize() {
    const apiKey = process.env.OPENAI_API_KEY;
    if (apiKey && apiKey.length > 20 && apiKey.startsWith('sk-')) {
      this.openai = new OpenAI({ apiKey });
      console.log('‚úÖ [AI] OpenAI inicializado com sucesso');
    } else {
      console.warn('‚ö†Ô∏è [AI] Chave da API OpenAI n√£o configurada');
    }
  }

  static async generateResponse(
    message: string,
    userContext: UserContext | null = null
  ): Promise<string> {
    const startTime = Date.now();
    let cached = false;

    try {
      // Verificar cache para mensagens similares
      const cacheKey = this.generateCacheKey(message, userContext);
      const cachedResponse = await CacheService.get(cacheKey);

      if (cachedResponse) {
        console.log('‚úÖ [AI] Resposta obtida do cache');
        cached = true;

        await MetricsService.trackInteraction({
          userId: userContext?.userProfile?.id,
          message,
          response: cachedResponse,
          processingTime: Date.now() - startTime,
          hasUserContext: !!userContext,
          cached: true
        });

        return cachedResponse;
      }

      // Gerar resposta com IA
      const response = await this.generateAIResponse(message, userContext);

      // Salvar no cache (exceto para usu√°rios com contexto personalizado)
      if (!userContext || userContext.activeAppointments.length === 0) {
        await CacheService.set(cacheKey, response, 1800000); // 30 minutos
      }

      // Rastrear m√©tricas
      await MetricsService.trackInteraction({
        userId: userContext?.userProfile?.id,
        message,
        response,
        processingTime: Date.now() - startTime,
        hasUserContext: !!userContext,
        cached: false
      });

      return response;

    } catch (error) {
      console.error('‚ùå [AI] Erro na gera√ß√£o de resposta:', error);

      // Rastrear erro
      await MetricsService.trackError(error, {
        userId: userContext?.userProfile?.id,
        message,
        hasUserContext: !!userContext
      });

      return this.getFallbackResponse(message, userContext);
    }
  }

  private static buildContextualPrompt(message: string, userContext: UserContext | null): string {
    const basePrompt = `Voc√™ √© Vandesson Santiago, advogado especialista em Direito de Fam√≠lia brasileiro.`;

    if (userContext) {
      console.log('ü§ñ [AI] Construindo prompt contextual:', {
        hasUserContext: !!userContext,
        userProfile: userContext.userProfile,
        userName: userContext.userProfile?.name,
        appointmentsCount: userContext.activeAppointments?.length || 0,
        casesCount: userContext.divorceCases?.length || 0
      });

      return `${basePrompt}

CONTEXTO DO USU√ÅRIO:
- Nome: ${userContext.userProfile?.name || 'N√£o informado'}
- Agendamentos ativos: ${userContext.activeAppointments?.length || 0}
- Casos de div√≥rcio: ${userContext.divorceCases?.length || 0}

INSTRU√á√ïES IMPORTANTES:
- SEMPRE use o nome do usu√°rio na sauda√ß√£o (exemplo: "Ol√°, Vandesson!")
- Se o usu√°rio perguntar sobre seu processo de div√≥rcio E voc√™ souber que ele tem casos ativos, mencione isso especificamente
- Se o usu√°rio tiver agendamentos ativos, mencione isso de forma √∫til e espec√≠fica
- Seja pessoal, amig√°vel e profissional
- Use as informa√ß√µes do contexto para dar respostas mais personalizadas

REFER√äNCIAS LEGAIS:
- SEMPRE inclua refer√™ncias legais espec√≠ficas e relevantes ao final das respostas
- Cite leis, c√≥digos e legisla√ß√£o aplic√°vel de forma clara e acess√≠vel
- Use formato: "üí° Base Legal: [Lei espec√≠fica] - [breve explica√ß√£o do que trata]"
- Exemplos:
  * Para div√≥rcio: "üí° Base Legal: Lei 11.441/2007 - Regula o div√≥rcio consensual extrajudicial"
  * Para guarda: "üí° Base Legal: Estatuto da Crian√ßa e do Adolescente (Lei 8.069/1990) - Protege direitos das crian√ßas"
  * Para pens√£o: "üí° Base Legal: C√≥digo Civil (Arts. 1.694-1.710) - Regula obriga√ß√£o alimentar"
- Mantenha as refer√™ncias concisas mas informativas
- S√≥ cite legisla√ß√£o diretamente relevante ao assunto discutido

Pergunta: ${message}`;
    }

    return `${basePrompt}\n\nPergunta: ${message}`;
  }

  private static getFallbackResponse(message: string, userContext: UserContext | null): string {
    const userName = userContext?.userProfile?.name || 'cliente';
    const appointmentsCount = userContext?.activeAppointments?.length || 0;
    const casesCount = userContext?.divorceCases?.length || 0;

    if (userContext && (appointmentsCount > 0 || casesCount > 0)) {
      let response = `Ol√°, ${userName}! `;

      if (casesCount > 0 && message.toLowerCase().includes('div√≥rcio')) {
        response += `Vejo que voc√™ tem ${casesCount} caso(s) de div√≥rcio em andamento. `;
      }

      if (appointmentsCount > 0) {
        response += `Voc√™ tamb√©m tem ${appointmentsCount} agendamento(s) ativo(s). `;
      }

      response += 'Como posso ajudar com sua quest√£o jur√≠dica hoje?';
      return response;
    }

    return 'Ol√°! Sou o advogado Vandesson Santiago, especialista em direito de fam√≠lia. Como posso ajudar com sua quest√£o jur√≠dica hoje?';
  }

  static isAvailable(): boolean {
    return !!this.openai;
  }

  private static generateCacheKey(message: string, userContext: UserContext | null): string {
    // Gerar chave baseada no conte√∫do da mensagem e contexto geral
    const baseKey = message.toLowerCase().trim().substring(0, 100);
    const contextKey = userContext ? 'authenticated' : 'anonymous';
    return `chat:${contextKey}:${baseKey}`;
  }

  private static async generateAIResponse(message: string, userContext: UserContext | null): Promise<string> {
    if (!this.openai) {
      console.warn('‚ö†Ô∏è [AI] OpenAI n√£o dispon√≠vel, usando resposta de fallback');
      return this.getFallbackResponse(message, userContext);
    }

    const prompt = this.buildContextualPrompt(message, userContext);

    const completion = await this.openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'system', content: prompt }],
      max_tokens: 400,
      temperature: 0.6,
    });

    const response = completion.choices[0]?.message?.content ||
      'Desculpe, n√£o consegui processar sua mensagem.';

    console.log('‚úÖ [AI] Resposta gerada com sucesso');
    return response;
  }
}
